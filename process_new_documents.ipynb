{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gcp_functions import *\n",
    "from os.path import splitext\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = os.getcwd()\n",
    "OUTPUT_FOLDER = \"output_truist_documentai\"\n",
    "BANK = \"Truist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(PATH, OUTPUT_FOLDER)):\n",
    "    os.mkdir(os.path.join(PATH, OUTPUT_FOLDER))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processor types:\n",
      "         INVOICE_PROCESSOR\n",
      "         CUSTOM_EXTRACTION_PROCESSOR\n",
      "         FORM_PARSER_PROCESSOR\n",
      "         OCR_PROCESSOR\n",
      "         FORM_W9_PROCESSOR\n",
      "         EXPENSE_PROCESSOR\n",
      "         US_DRIVER_LICENSE_PROCESSOR\n",
      "         US_PASSPORT_PROCESSOR\n",
      "         ID_PROOFING_PROCESSOR\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"\"\"Processor types:\n",
    "         INVOICE_PROCESSOR\n",
    "         CUSTOM_EXTRACTION_PROCESSOR\n",
    "         FORM_PARSER_PROCESSOR\n",
    "         OCR_PROCESSOR\n",
    "         FORM_W9_PROCESSOR\n",
    "         EXPENSE_PROCESSOR\n",
    "         US_DRIVER_LICENSE_PROCESSOR\n",
    "         US_PASSPORT_PROCESSOR\n",
    "         ID_PROOFING_PROCESSOR\"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projects/819948058680/locations/us/operations/4290722472672428289\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    create_processor_sample(\n",
    "        project_id=\"un-analitica-avanzada\",\n",
    "        location=\"us\",\n",
    "        processor_display_name=\"test_document_ai_form_parse\",\n",
    "        processor_type=\"FORM_PARSER_PROCESSOR\"\n",
    "    )\n",
    "except:\n",
    "    enable_processor_sample(\n",
    "        project_id=\"un-analitica-avanzada\", \n",
    "        location=\"us\", \n",
    "        processor_id=\"695bea31f0e5bd8d\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"un-analitica-avanzada\"\n",
    "LOCATION = \"us\"  # Format is 'us' or 'eu'\n",
    "PROCESSOR_ID = \"695bea31f0e5bd8d\"  # Create processor before running sample\n",
    "\n",
    "# Refer to https://cloud.google.com/document-ai/docs/file-types\n",
    "# for supported file types\n",
    "MIME_TYPE = \"application/pdf\"\n",
    "GCS_OUTPUT_BUCKET = \"gs://test_documentai_process\"\n",
    "GCS_OUTPUT_URI_PREFIX = \"new_output_documentai_process\"\n",
    "\n",
    "INPUT_FOLDER = \"new_inputs_doc\"\n",
    "BUCKET_NAME = \"test_documentai_process\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "subfolders = get_subfolders_names(bucket_name=BUCKET_NAME, folder_name=INPUT_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for operation projects/819948058680/locations/us/operations/15061231872848256275 to complete...\n",
      "Output files:\n",
      "Fetching new_output_documentai_process/15061231872848256275/0/October, 2021 (1)-0.json\n",
      "October, 2021 (1)\n",
      "Page 1 - Table 0\n",
      "Page 1 - Table 1\n",
      "Page 1 - Table 2\n",
      "Page 2 - Table 0\n",
      "Waiting for operation projects/819948058680/locations/us/operations/10503702188275173891 to complete...\n",
      "Output files:\n",
      "Fetching new_output_documentai_process/10503702188275173891/0/October, 2021-0.json\n",
      "October, 2021\n",
      "Page 1 - Table 0\n",
      "Page 1 - Table 1\n",
      "Page 1 - Table 2\n",
      "Page 2 - Table 0\n",
      "Waiting for operation projects/819948058680/locations/us/operations/1277910807421158699 to complete...\n",
      "Output files:\n",
      "Fetching new_output_documentai_process/1277910807421158699/0/September, 2021-0.json\n",
      "September, 2021\n",
      "Page 1 - Table 0\n",
      "Page 1 - Table 1\n",
      "Page 1 - Table 2\n",
      "Page 2 - Table 0\n"
     ]
    }
   ],
   "source": [
    "for subfolder in subfolders:\n",
    "    \n",
    "    if subfolder == BANK:\n",
    "        \n",
    "        file_names = get_files_names(bucket_name=BUCKET_NAME, \n",
    "                                     master_folder=INPUT_FOLDER,\n",
    "                                     folder_name=subfolder)\n",
    "        \n",
    "        for idx, file_name in enumerate(file_names):\n",
    "            gcs_input_uri = GCS_OUTPUT_BUCKET + \"/\" + INPUT_FOLDER + \"/\" + subfolder + \"/\" + file_name\n",
    "\n",
    "            list_document = batch_process_documents(\n",
    "                            project_id=PROJECT_ID,\n",
    "                            location=LOCATION,\n",
    "                            processor_id=PROCESSOR_ID,\n",
    "                            gcs_input_uri=gcs_input_uri,\n",
    "                            input_mime_type=MIME_TYPE,\n",
    "                            gcs_output_bucket=GCS_OUTPUT_BUCKET,\n",
    "                            gcs_output_uri_prefix=GCS_OUTPUT_URI_PREFIX\n",
    "            )\n",
    "\n",
    "            for document in list_document:\n",
    "                \n",
    "                header_row_values: List[List[str]] = []\n",
    "                body_row_values: List[List[str]] = []\n",
    "\n",
    "                # Input Filename without extension\n",
    "                output_file_prefix = file_name.split(\".pdf\")[0]\n",
    "                print(output_file_prefix)\n",
    "\n",
    "                dic_tables = {}\n",
    "                \n",
    "                for page in document.pages:\n",
    "                    \n",
    "                    for index, table in enumerate(page.tables):\n",
    "                        header_row_values = get_table_data(table.header_rows, document.text)\n",
    "                        body_row_values = get_table_data(table.body_rows, document.text)\n",
    "\n",
    "                        # Create a Pandas Dataframe to print the values in tabular format.\n",
    "                        df = pd.DataFrame(\n",
    "                            data=body_row_values,\n",
    "                            columns=pd.MultiIndex.from_arrays(header_row_values),\n",
    "                        )\n",
    "\n",
    "                        print(f\"Page {page.page_number} - Table {index}\")\n",
    "                        dic_tables[\"page_\" + str(page.page_number) + \"_table_\"+ str(index)] = df\n",
    "                        # print(df)\n",
    "                        \n",
    "                        folder = \"file_\" + str(idx)\n",
    "                        \n",
    "                        if not os.path.exists(os.path.join(PATH, OUTPUT_FOLDER, folder)):\n",
    "                            os.mkdir(os.path.join(PATH, OUTPUT_FOLDER, folder))\n",
    "                        \n",
    "                        \n",
    "                        # Save each table as a CSV file\n",
    "                        output_filename = f\"{output_file_prefix}_pg{page.page_number}_tb{index}.csv\"\n",
    "                        df.to_csv(os.path.join(PATH, OUTPUT_FOLDER, folder, output_filename), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projects/819948058680/locations/us/operations/17836418868320990590\n"
     ]
    }
   ],
   "source": [
    "disable_processor_sample(\n",
    "    project_id=\"un-analitica-avanzada\",\n",
    "    location=\"us\",\n",
    "    processor_id=\"695bea31f0e5bd8d\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b7a37235a2a0b468d2679cea264852352efd4af2e267d85e36c7b7619b001185"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
